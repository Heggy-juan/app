import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.pipeline import Pipeline
import warnings

# è§£å†³Streamlitè¿è¡Œç¯å¢ƒé—®é¢˜
if "streamlit" not in sys.modules:
    os.environ["STREAMLIT_SERVER_PORT"] = "8501"
    os.environ["STREAMLIT_SERVER_ADDRESS"] = "0.0.0.0"
    os.environ["STREAMLIT_SERVER_HEADLESS"] = "true"
    
    from streamlit.web.bootstrap import run
    sys.argv = ["streamlit", "run", sys.argv[0], "--global.developmentMode=false"]
    sys.exit(run())

warnings.filterwarnings("ignore", category=UserWarning)

# å¤šè¯­è¨€æ”¯æŒ
LANGUAGES = {
    "ä¸­æ–‡": {
        "title": "æœºå™¨å­¦ä¹ å›å½’æ¨¡å‹é¢„æµ‹å¹³å°",
        "upload": "ä¸Šä¼ Excelæ•°æ®æ–‡ä»¶ (ä¾‹: å›¢ç°‡+å•åŸå­-åˆ†å¼€ç®—.xlsx)",
        "decimal": "ä¿ç•™å°æ•°ä½æ•°",
        "model_perf": "æ¨¡å‹æ€§èƒ½å¯¹æ¯”",
        "best_model": "å½“å‰æ•°æ®è¡¨ç°æœ€ä¼˜çš„æ¨¡å‹ä¸º",
        "tuning": "è‡ªåŠ¨è°ƒå‚",
        "final_perf": "æœ€ç»ˆæ¨¡å‹åœ¨æµ‹è¯•é›†è¡¨ç°",
        "prediction": "è¾“å…¥ç‰¹å¾åšé¢„æµ‹",
        "compound": "åŒ–åˆç‰©åç§°",
        "paste": "å¯ç›´æ¥ç²˜è´´ç‰¹å¾å€¼ï¼ˆä»¥Tabã€é€—å·ã€ç©ºæ ¼æˆ–å›è½¦åˆ†éš”ï¼‰",
        "predict_btn": "é¢„æµ‹",
        "result": "é¢„æµ‹ç»“æœ",
        "raw_data": "åŸå§‹æ•°æ®",
        "upload_info": "è¯·å…ˆä¸Šä¼ åŒ…å«'OERè¿‡ç”µåŠ¿'å’Œ'ORRè¿‡ç”µåŠ¿'ä¸¤åˆ—çš„Excelæ–‡ä»¶",
        "error_columns": "æœªæ£€æµ‹åˆ°'OERè¿‡ç”µåŠ¿'å’Œ'ORRè¿‡ç”µåŠ¿'ä¸¤åˆ—ï¼Œè¯·ç¡®è®¤æ•°æ®æ ¼å¼å’Œè¡¨å¤´ï¼",
        "error_data": "ç‰¹å¾åˆ—æˆ–ç›®æ ‡åˆ—ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®ï¼",
        "error_paste": "ç²˜è´´çš„æ•°æ®æ•°é‡æˆ–æ ¼å¼ä¸å¯¹ï¼Œè¯·æ£€æŸ¥ï¼",
        "features_error": "ç‰¹å¾æ•°é‡é”™è¯¯",
        "no_tuning": "æ— éœ€è°ƒå‚",
        "download": "ä¸‹è½½é¢„æµ‹ç»“æœ",
        "features": "ç‰¹å¾æ•°é‡",
        "samples": "æ ·æœ¬æ•°é‡",
        "data_overview": "æ•°æ®æ¦‚è§ˆ",
        "model_training": "æ¨¡å‹è®­ç»ƒ",
        "prediction_section": "åŒ–åˆç‰©é¢„æµ‹",
        "data_analysis": "æ•°æ®åˆ†æ",
        "app_intro": "åº”ç”¨ä»‹ç»",
        "feature_corr": "ç‰¹å¾ç›¸å…³æ€§",
        "data_dist": "æ•°æ®åˆ†å¸ƒ",
        "history_pred": "å†å²é¢„æµ‹è®°å½•"
    },
    "English": {
        "title": "Machine Learning Regression Prediction Platform",
        "upload": "Upload Excel Data File (e.g. cluster+single_atom.xlsx)",
        "decimal": "Decimal Places",
        "model_perf": "Model Performance Comparison",
        "best_model": "Best Performing Model for Current Data",
        "tuning": "Automatic Hyperparameter Tuning",
        "final_perf": "Final Model Performance on Test Set",
        "prediction": "Input Features for Prediction",
        "compound": "Compound Name",
        "paste": "Paste feature values (separated by Tab, comma, space or Enter)",
        "predict_btn": "Predict",
        "result": "Prediction Result",
        "raw_data": "Raw Data",
        "upload_info": "Please upload an Excel file containing 'OER Overpotential' and 'ORR Overpotential' columns",
        "error_columns": "Required columns 'OER Overpotential' and 'ORR Overpotential' not found. Please check data format and headers!",
        "error_data": "Feature columns or target columns are empty. Please check data!",
        "error_paste": "Pasted data format is incorrect. Please check!",
        "features_error": "Feature count error",
        "no_tuning": "No tuning required",
        "download": "Download Prediction Results",
        "features": "Number of Features",
        "samples": "Number of Samples",
        "data_overview": "Data Overview",
        "model_training": "Model Training",
        "prediction_section": "Compound Prediction",
        "data_analysis": "Data Analysis",
        "app_intro": "Application Introduction",
        "feature_corr": "Feature Correlation",
        "data_dist": "Data Distribution",
        "history_pred": "Prediction History"
    },
    "EspaÃ±ol": {
        "title": "Plataforma de PredicciÃ³n de Modelos de RegresiÃ³n de Aprendizaje AutomÃ¡tico",
        "upload": "Cargar archivo Excel de datos (ej. cluster+single_atom.xlsx)",
        "decimal": "Decimales",
        "model_perf": "ComparaciÃ³n de Rendimiento de Modelos",
        "best_model": "Modelo de Mejor Rendimiento para los Datos Actuales",
        "tuning": "Ajuste AutomÃ¡tico de HiperparÃ¡metros",
        "final_perf": "Rendimiento Final del Modelo en Conjunto de Prueba",
        "prediction": "Ingresar CaracterÃ­sticas para PredicciÃ³n",
        "compound": "Nombre del Compuesto",
        "paste": "Pegar valores de caracterÃ­sticas (separados por Tab, coma, espacio o Enter)",
        "predict_btn": "Predecir",
        "result": "Resultado de PredicciÃ³n",
        "raw_data": "Datos Crudos",
        "upload_info": "Por favor cargue un archivo Excel que contenga las columnas 'Sobrepotencial OER' y 'Sobrepotencial ORR'",
        "error_columns": "Columnas requeridas 'Sobrepotencial OER' y 'Sobrepotencial ORR' no encontradas. Â¡Por favor verifique el formato de datos y encabezados!",
        "error_data": "Las columnas de caracterÃ­sticas o las columnas objetivo estÃ¡n vacÃ­as. Â¡Por favor verifique los datos!",
        "error_paste": "El formato de los datos pegados es incorrecto. Â¡Por favor verifique!",
        "features_error": "Error en el recuento de caracterÃ­sticas",
        "no_tuning": "No se requiere ajuste",
        "download": "Descargar Resultados de PredicciÃ³n",
        "features": "NÃºmero de CaracterÃ­sticas",
        "samples": "NÃºmero de Muestras",
        "data_overview": "Resumen de Datos",
        "model_training": "Entrenamiento de Modelo",
        "prediction_section": "PredicciÃ³n de Compuesto",
        "data_analysis": "AnÃ¡lisis de Datos",
        "app_intro": "IntroducciÃ³n de la AplicaciÃ³n",
        "feature_corr": "CorrelaciÃ³n de CaracterÃ­sticas",
        "data_dist": "DistribuciÃ³n de Datos",
        "history_pred": "Historial de Predicciones"
    },
    "æ—¥æœ¬èª": {
        "title": "æ©Ÿæ¢°å­¦ç¿’å›å¸°ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ",
        "upload": "Excelãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä¾‹: cluster+single_atom.xlsxï¼‰",
        "decimal": "å°æ•°ç‚¹ä»¥ä¸‹ã®æ¡æ•°",
        "model_perf": "ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ",
        "best_model": "ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã§æœ€é©ãªãƒ¢ãƒ‡ãƒ«",
        "tuning": "è‡ªå‹•ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°",
        "final_perf": "ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®æœ€çµ‚ãƒ¢ãƒ‡ãƒ«æ€§èƒ½",
        "prediction": "äºˆæ¸¬ã®ãŸã‚ã®ç‰¹å¾´é‡å…¥åŠ›",
        "compound": "åŒ–åˆç‰©å",
        "paste": "ç‰¹å¾´é‡ã‚’è²¼ã‚Šä»˜ã‘ï¼ˆã‚¿ãƒ–ã€ã‚«ãƒ³ãƒã€ã‚¹ãƒšãƒ¼ã‚¹ã¾ãŸã¯æ”¹è¡Œã§åŒºåˆ‡ã‚‹ï¼‰",
        "predict_btn": "äºˆæ¸¬",
        "result": "äºˆæ¸¬çµæœ",
        "raw_data": "ç”Ÿãƒ‡ãƒ¼ã‚¿",
        "upload_info": "'OERéé›»åœ§'ã¨'ORRéé›»åœ§'ã®åˆ—ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        "error_columns": "å¿…è¦ãªåˆ—'OERéé›»åœ§'ã¨'ORRéé›»åœ§'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿å½¢å¼ã¨ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼",
        "error_data": "ç‰¹å¾´é‡åˆ—ã¾ãŸã¯ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ãŒç©ºã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼",
        "error_paste": "è²¼ã‚Šä»˜ã‘ãŸãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚ç¢ºèªã—ã¦ãã ã•ã„ï¼",
        "features_error": "ç‰¹å¾´é‡æ•°ã‚¨ãƒ©ãƒ¼",
        "no_tuning": "ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦",
        "download": "äºˆæ¸¬çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        "features": "ç‰¹å¾´é‡ã®æ•°",
        "samples": "ã‚µãƒ³ãƒ—ãƒ«æ•°",
        "data_overview": "ãƒ‡ãƒ¼ã‚¿æ¦‚è¦",
        "model_training": "ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
        "prediction_section": "åŒ–åˆç‰©äºˆæ¸¬",
        "data_analysis": "ãƒ‡ãƒ¼ã‚¿åˆ†æ",
        "app_intro": "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç´¹ä»‹",
        "feature_corr": "ç‰¹å¾´é‡ç›¸é–¢",
        "data_dist": "ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ",
        "history_pred": "äºˆæ¸¬å±¥æ­´"
    }
}

# åˆå§‹åŒ–Session State
if 'language' not in st.session_state:
    st.session_state.language = "ä¸­æ–‡"
if 'prediction_results' not in st.session_state:
    st.session_state.prediction_results = []
if 'df' not in st.session_state:
    st.session_state.df = None
if 'best_model' not in st.session_state:
    st.session_state.best_model = None
if 'y_cols' not in st.session_state:
    st.session_state.y_cols = ['OERè¿‡ç”µåŠ¿', 'ORRè¿‡ç”µåŠ¿']

# è¯­è¨€é€‰æ‹©å™¨
def set_language():
    st.session_state.language = st.session_state.lang_select
    # æ ¹æ®è¯­è¨€æ›´æ–°ç›®æ ‡åˆ—å
    lang = st.session_state.language
    if lang == "ä¸­æ–‡":
        st.session_state.y_cols = ['OERè¿‡ç”µåŠ¿', 'ORRè¿‡ç”µåŠ¿']
    elif lang == "English":
        st.session_state.y_cols = ['OER Overpotential', 'ORR Overpotential']
    elif lang == "EspaÃ±ol":
        st.session_state.y_cols = ['Sobrepotencial OER', 'Sobrepotencial ORR']
    elif lang == "æ—¥æœ¬èª":
        st.session_state.y_cols = ['OERéé›»åœ§', 'ORRéé›»åœ§']

# è·å–å½“å‰è¯­è¨€æ–‡æœ¬
def t(key):
    return LANGUAGES[st.session_state.language][key]

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
def add_custom_css():
    st.markdown("""
    <style>
        /* ä¸»æ ‡é¢˜æ ·å¼ */
        .stApp header h1 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        
        /* ä¾§è¾¹æ æ ·å¼ */
        [data-testid="stSidebar"] {
            background: linear-gradient(135deg, #2c3e50, #4a6491);
            color: white;
        }
        
        [data-testid="stSidebar"] .stButton button {
            background-color: #3498db;
            color: white;
            border-radius: 5px;
        }
        
        [data-testid="stSidebar"] .stButton button:hover {
            background-color: #2980b9;
        }
        
        /* å¡ç‰‡æ ·å¼ */
        .card {
            background-color: #f8f9fa;
            border-radius: 10px;
            padding: 15px;
            margin: 10px 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        
        /* æŒ‰é’®æ ·å¼ */
        .stButton button {
            background-color: #3498db;
            color: white;
            border-radius: 5px;
            transition: all 0.3s;
        }
        
        .stButton button:hover {
            background-color: #2980b9;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }
        
        /* è¡¨å•æ ·å¼ */
        .stForm {
            background-color: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        
        /* æŒ‡æ ‡å¡æ ·å¼ */
        .metric {
            background-color: white;
            border-radius: 10px;
            padding: 15px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            text-align: center;
        }
        
        /* é¡µè„šæ ·å¼ */
        .footer {
            position: fixed;
            bottom: 0;
            width: 100%;
            background-color: #2c3e50;
            color: white;
            text-align: center;
            padding: 10px;
            z-index: 100;
        }
    </style>
    """, unsafe_allow_html=True)

# æ–‡ä»¶ä¸Šä¼ ä¸å¤„ç†
def handle_file_upload():
    uploaded_file = st.file_uploader(t("upload"), type=['xlsx'])
    
    if uploaded_file is not None:
        try:
            df = pd.read_excel(uploaded_file, header=1)
        except Exception as e:
            st.error(f"Excelæ–‡ä»¶è¯»å–å¤±è´¥ï¼š{e}")
            return None
        
        # è‡ªåŠ¨æ£€æµ‹è¡¨å¤´è¡Œ
        if not all(col in df.columns for col in st.session_state.y_cols):
            try:
                df = pd.read_excel(uploaded_file, header=2)
            except:
                pass

        if not all(col in df.columns for col in st.session_state.y_cols):
            st.error(t("error_columns"))
            return None

        compound_col = df.columns[0]
        df = df.dropna(subset=st.session_state.y_cols)
        return df
    
    return None

# è®­ç»ƒæ¨¡å‹
def train_models(X, Y):
    # åˆ†å‰²æ•°æ®é›†
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

    models = {
        "Linear Regression": Pipeline([("scaler", StandardScaler()), ("model", LinearRegression())]),
        "Ridge Regression": Pipeline([("scaler", StandardScaler()), ("model", Ridge(alpha=1.0))]),
        "Lasso Regression": Pipeline([("scaler", StandardScaler()), ("model", Lasso(alpha=0.1))]),
        "Random Forest": MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)),
        "Gradient Boosting": MultiOutputRegressor(GradientBoostingRegressor(n_estimators=100, random_state=42))
    }

    results = {}
    best_score = -np.inf
    best_model_name = None
    best_model_object = None

    # æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
    with st.spinner(t("model_perf")):
        for name, model in models.items():
            model.fit(X_train, Y_train)
            Y_pred = model.predict(X_test)
            mse = mean_squared_error(Y_test, Y_pred)
            mae = mean_absolute_error(Y_test, Y_pred)
            r2 = r2_score(Y_test, Y_pred)
            cv_score = cross_val_score(model, X, Y, cv=5, scoring='r2').mean()
            results[name] = {
                "MSE": mse,
                "MAE": mae,
                "RÂ²": r2,
                "CV RÂ²": cv_score
            }
            if cv_score > best_score:
                best_score = cv_score
                best_model_name = name
                best_model_object = model

    # è‡ªåŠ¨è°ƒå‚
    param_grids = {
        "Random Forest": {
            "estimator__n_estimators": [100, 200],
            "estimator__max_depth": [5, 10, None]
        },
        "Gradient Boosting": {
            "estimator__n_estimators": [100, 200],
            "estimator__max_depth": [3, 5, None]
        },
        "Ridge Regression": {
            "model__alpha": [0.01, 0.1, 1.0, 10.0]
        },
        "Lasso Regression": {
            "model__alpha": [0.01, 0.1, 1.0, 10.0]
        }
    }

    if best_model_name in param_grids:
        st.info(f"{t('tuning')} {best_model_name}...")
        if best_model_name == "Random Forest":
            base_estimator = MultiOutputRegressor(RandomForestRegressor(random_state=42))
            param_grid = param_grids["Random Forest"]
        elif best_model_name == "Gradient Boosting":
            base_estimator = MultiOutputRegressor(GradientBoostingRegressor(random_state=42))
            param_grid = param_grids["Gradient Boosting"]
        elif best_model_name == "Ridge Regression":
            base_estimator = Pipeline([("scaler", StandardScaler()), ("model", Ridge())])
            param_grid = param_grids["Ridge Regression"]
        elif best_model_name == "Lasso Regression":
            base_estimator = Pipeline([("scaler", StandardScaler()), ("model", Lasso())])
            param_grid = param_grids["Lasso Regression"]

        grid = GridSearchCV(base_estimator, param_grid, cv=5, n_jobs=-1)
        grid.fit(X_train, Y_train)
        best_params = grid.best_params_
        st.write(f"{best_model_name} {t('best_model')}: {best_params}")
        best_model_object = grid.best_estimator_
    else:
        st.info(f"{best_model_name} {t('no_tuning')}")
    
    return results, best_model_object, best_model_name, best_score, X_test, Y_test

# ä¸»åº”ç”¨
def main():
    add_custom_css()
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("è®¾ç½®")
        st.selectbox(
            "é€‰æ‹©è¯­è¨€ / Language", 
            list(LANGUAGES.keys()), 
            key="lang_select", 
            on_change=set_language
        )
        
        decimal_places = st.selectbox(t("decimal"), [1, 2, 3, 4, 5], index=2)
        
        st.markdown("---")
        st.subheader(t("prediction"))
        st.info(t("paste"))
        
        st.markdown("---")
        st.subheader("å…³äº")
        st.markdown("""
        æ­¤åº”ç”¨ä½¿ç”¨å¤šç§æœºå™¨å­¦ä¹ å›å½’æ¨¡å‹é¢„æµ‹åŒ–åˆç‰©çš„OERå’ŒORRè¿‡ç”µåŠ¿ã€‚
        - æ”¯æŒçº¿æ€§å›å½’ã€å²­å›å½’ã€Lassoå›å½’ã€éšæœºæ£®æ—å’Œæ¢¯åº¦æå‡æ ‘
        - è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹å¹¶è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜
        - æä¾›æ‰¹é‡ç‰¹å¾å€¼é¢„æµ‹åŠŸèƒ½
        """)
        
        st.markdown("---")
        st.caption("Â© 2023 æœºå™¨å­¦ä¹ é¢„æµ‹å¹³å° | ç‰ˆæœ¬ 1.2.0")
    
    # ä¸»ç•Œé¢
    st.title(t("title"))
    
    # æ–‡ä»¶ä¸Šä¼ ä¸å¤„ç†
    if st.session_state.df is None:
        st.session_state.df = handle_file_upload()
    
    # æ•°æ®æ¦‚è§ˆ
    if st.session_state.df is not None:
        df = st.session_state.df
        compound_col = df.columns[0]
        X = df.drop([compound_col] + st.session_state.y_cols, axis=1).select_dtypes(include='number')
        Y = df[st.session_state.y_cols].astype(float)
        
        if X.empty or Y.empty:
            st.error(t("error_data"))
            st.stop()
        
        # æ•°æ®æ¦‚è§ˆå¡ç‰‡
        st.subheader(t("data_overview"))
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric(t("samples"), len(df))
        with col2:
            st.metric(t("features"), len(X.columns))
        with col3:
            st.metric("ç›®æ ‡å˜é‡", len(st.session_state.y_cols))
        
        # æ¨¡å‹è®­ç»ƒ
        st.subheader(t("model_training"))
        if st.button("å¼€å§‹è®­ç»ƒæ¨¡å‹") or st.session_state.best_model is not None:
            if st.session_state.best_model is None:
                results, best_model, best_model_name, best_score, X_test, Y_test = train_models(X, Y)
                st.session_state.best_model = best_model
                st.session_state.results = results
                st.session_state.best_model_name = best_model_name
                st.session_state.best_score = best_score
                st.session_state.X_test = X_test
                st.session_state.Y_test = Y_test
            
            # æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”
            results_df = pd.DataFrame(st.session_state.results).T
            st.subheader(t("model_perf"))
            
            # æ ¼å¼åŒ–æ˜¾ç¤º
            formatted_results = results_df.copy()
            for col in formatted_results.columns:
                formatted_results[col] = formatted_results[col].apply(lambda x: f"{x:.{decimal_places}f}")
            
            st.dataframe(formatted_results.sort_values(by="CV RÂ²", ascending=False))
            
            st.success(f"{t('best_model')}ï¼š{st.session_state.best_model_name}ï¼ˆCV RÂ² = {st.session_state.best_score:.{decimal_places}f}ï¼‰")
            
            # æµ‹è¯•é›†æœ€ç»ˆè¡¨ç°
            Y_pred = st.session_state.best_model.predict(st.session_state.X_test)
            st.subheader(t("final_perf"))
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("MSE", f"{mean_squared_error(st.session_state.Y_test, Y_pred):.{decimal_places}f}")
            with col2:
                st.metric("MAE", f"{mean_absolute_error(st.session_state.Y_test, Y_pred):.{decimal_places}f}")
            with col3:
                st.metric("RÂ²", f"{r2_score(st.session_state.Y_test, Y_pred):.{decimal_places}f}")
            
            # é¢„æµ‹è¡¨å•
            st.subheader(t("prediction_section"))
            with st.form("predict_form"):
                compound_name = st.text_input(t("compound"), "æ–°åŒ–åˆç‰©")
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(t("paste"))
                with col2:
                    example_features = ", ".join([f"{np.random.uniform(0, 1):.3f}" for _ in range(len(X.columns))])
                    st.caption(f"ç¤ºä¾‹: {example_features}")
                
                # ä¿®å¤é«˜åº¦é—®é¢˜
                pasted_features = st.text_area("", value="", height=70, label_visibility="collapsed")
    
                feature_values = []
                valid_paste = False
                if pasted_features.strip():
                    raw = pasted_features.replace('\n', ' ').replace('\r', ' ')
                    for sep in ['\t', ',', ' ']:
                        parts = [x for x in raw.split(sep) if x.strip() != ""]
                        if len(parts) == len(X.columns):
                            try:
                                feature_values = [float(x) for x in parts]
                                valid_paste = True
                                break
                            except:
                                pass
                    if not valid_paste:
                        st.error(f"{t('error_paste')}ï¼ˆéœ€è¦ {len(X.columns)} ä¸ªç‰¹å¾ï¼‰")
    
                if not valid_paste:
                    feature_values = [float(X[col].mean()) for col in X.columns]
    
                # ç‰¹å¾è¾“å…¥æ¡†
                cols = st.columns(3)
                col_idx = 0
                for i, col in enumerate(X.columns):
                    with cols[col_idx]:
                        feature_values[i] = st.number_input(f"{col}", value=feature_values[i], step=0.01)
                    col_idx = (col_idx + 1) % 3
                
                # æ·»åŠ æäº¤æŒ‰é’®
                submit_btn = st.form_submit_button(t("predict_btn"))
            
            # å¤„ç†é¢„æµ‹è¯·æ±‚
            if submit_btn:
                if len(feature_values) != X.shape[1]:
                    st.error(f"{t('features_error')}ï¼Œéœ€è¦ {X.shape[1]} ä¸ªã€‚")
                else:
                    input_df = pd.DataFrame([feature_values], columns=X.columns)
                    prediction = st.session_state.best_model.predict(input_df)
                    
                    # ä¿å­˜é¢„æµ‹ç»“æœ
                    result = {
                        "Compound": compound_name,
                        "Features": feature_values.copy(),
                        "OER": prediction[0][0],
                        "ORR": prediction[0][1]
                    }
                    st.session_state.prediction_results.append(result)
                    
                    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                    st.success(f"{compound_name} {t('result')}ï¼š")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric(
                            label=st.session_state.y_cols[0], 
                            value=f"{prediction[0][0]:.{decimal_places}f} V",
                            delta=None
                        )
                    with col2:
                        st.metric(
                            label=st.session_state.y_cols[1], 
                            value=f"{prediction[0][1]:.{decimal_places}f} V",
                            delta=None
                        )
            
            # æ˜¾ç¤ºå†å²é¢„æµ‹ç»“æœ
            if st.session_state.prediction_results:
                st.subheader(t("history_pred"))
                history_df = pd.DataFrame(st.session_state.prediction_results)
                history_display = history_df[["Compound", "OER", "ORR"]]
                st.dataframe(history_display.style.format({
                    'OER': f"{{:.{decimal_places}f}}",
                    'ORR': f"{{:.{decimal_places}f}}"
                }))
                
                # ä¸‹è½½é¢„æµ‹ç»“æœ
                csv = history_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label=t("download"),
                    data=csv,
                    file_name='prediction_results.csv',
                    mime='text/csv'
                )
            
            # æ•°æ®åˆ†æ
            st.subheader(t("data_analysis"))
            
            # æ•°æ®å¯è§†åŒ–
            tab1, tab2 = st.tabs([t("data_dist"), t("feature_corr")])
            
            with tab1:
                st.subheader(t("data_dist"))
                col1, col2 = st.columns(2)
                with col1:
                    st.bar_chart(df[st.session_state.y_cols[0]].value_counts())
                with col2:
                    st.bar_chart(df[st.session_state.y_cols[1]].value_counts())
            
            with tab2:
                st.subheader(t("feature_corr"))
                corr = X.corr()
                st.dataframe(corr.style.background_gradient(cmap='coolwarm', axis=None).format("{:.2f}"))
            
            # åŸå§‹æ•°æ®å±•ç¤º
            with st.expander(f"ğŸ“Š {t('raw_data')}"):
                st.dataframe(df)
    else:
        # åº”ç”¨ä»‹ç»
        st.info(t("upload_info"))
        
        # åº”ç”¨åŠŸèƒ½ä»‹ç»
        with st.expander(t("app_intro")):
            st.markdown(f"""
            ### {t('app_intro')}
            
            **{t('title')}** æ˜¯ä¸€ä¸ªç”¨äºé¢„æµ‹åŒ–åˆç‰©OERå’ŒORRè¿‡ç”µåŠ¿çš„å·¥å…·ï¼Œå…·æœ‰ä»¥ä¸‹åŠŸèƒ½ï¼š
            
            1. **å¤šè¯­è¨€æ”¯æŒ**ï¼š
               - æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ã€è¥¿ç­ç‰™æ–‡å’Œæ—¥æ–‡ç•Œé¢
               - å®æ—¶åˆ‡æ¢è¯­è¨€
            
            2. **æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°**ï¼š
               - æ”¯æŒå¤šç§æœºå™¨å­¦ä¹ å›å½’æ¨¡å‹ï¼ˆçº¿æ€§å›å½’ã€å²­å›å½’ã€Lassoå›å½’ã€éšæœºæ£®æ—ã€æ¢¯åº¦æå‡æ ‘ï¼‰
               - è‡ªåŠ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½å¹¶é€‰æ‹©æœ€ä½³æ¨¡å‹
               - æä¾›è¯¦ç»†çš„æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼ˆMSEã€MAEã€RÂ²ã€CV RÂ²ï¼‰
            
            3. **è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜**ï¼š
               - å¯¹é€‰æ‹©çš„æ¨¡å‹è‡ªåŠ¨è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
               - æ˜¾ç¤ºæœ€ä¼˜å‚æ•°ç»„åˆ
            
            4. **é¢„æµ‹åŠŸèƒ½**ï¼š
               - æ”¯æŒå•æ¬¡é¢„æµ‹
               - æ‰¹é‡ç²˜è´´ç‰¹å¾å€¼è¿›è¡Œé¢„æµ‹
               - ä¿å­˜å†å²é¢„æµ‹è®°å½•
               - å¯è§†åŒ–é¢„æµ‹ç»“æœ
            
            5. **æ•°æ®åˆ†æ**ï¼š
               - æ•°æ®åˆ†å¸ƒå¯è§†åŒ–
               - ç‰¹å¾ç›¸å…³æ€§åˆ†æ
               - åŸå§‹æ•°æ®å±•ç¤º
            
            ### ä½¿ç”¨è¯´æ˜
            
            1. **ä¸Šä¼ æ•°æ®**ï¼š
               - ä¸Šä¼ åŒ…å«'OERè¿‡ç”µåŠ¿'å’Œ'ORRè¿‡ç”µåŠ¿'ä¸¤åˆ—çš„Excelæ–‡ä»¶
               - ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®ï¼ˆç¬¬ä¸€åˆ—ä¸ºåŒ–åˆç‰©åç§°ï¼Œåç»­åˆ—ä¸ºç‰¹å¾å€¼ï¼‰
            
            2. **æ¨¡å‹è®­ç»ƒ**ï¼š
               - ç‚¹å‡»"å¼€å§‹è®­ç»ƒæ¨¡å‹"æŒ‰é’®
               - ç³»ç»Ÿä¼šè‡ªåŠ¨è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶è¯„ä¼°æ€§èƒ½
               - é€‰æ‹©æœ€ä½³æ¨¡å‹å¹¶è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
            
            3. **é¢„æµ‹åŒ–åˆç‰©**ï¼š
               - è¾“å…¥åŒ–åˆç‰©åç§°
               - ç²˜è´´æˆ–è¾“å…¥ç‰¹å¾å€¼
               - ç‚¹å‡»"é¢„æµ‹"æŒ‰é’®æŸ¥çœ‹ç»“æœ
            
            4. **ç»“æœåˆ†æ**ï¼š
               - æŸ¥çœ‹é¢„æµ‹ç»“æœï¼ˆOERå’ŒORRè¿‡ç”µåŠ¿ï¼‰
               - åˆ†æå†å²é¢„æµ‹è®°å½•
               - ä¸‹è½½é¢„æµ‹ç»“æœ
            """)
    
    # é¡µè„š - å±…ä¸­æ˜¾ç¤º
    st.markdown("""
    <div class="footer">
        <p style="text-align: center; width: 100%;">æœºå™¨å­¦ä¹ é¢„æµ‹å¹³å° Â© 2023 | æŠ€æœ¯æ”¯æŒ: support@mlprediction.com</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()